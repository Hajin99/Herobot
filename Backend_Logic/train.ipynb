{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1272, 30, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = [\n",
    "    'come',\n",
    "    'away',\n",
    "    'spin'\n",
    "]\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load('dataset/seq_come_1627646273.npy'),\n",
    "    np.load('dataset/seq_away_1627646273.npy'),\n",
    "    np.load('dataset/seq_spin_1627646273.npy')\n",
    "], axis=0)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1272, 30, 99)\n",
      "(1272,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1272, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1144, 30, 99) (1144, 3)\n",
      "(128, 30, 99) (128, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c/Library/Python/3.9/lib/python/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m41,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,163</span> (172.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,163\u001b[0m (172.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,163</span> (172.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,163\u001b[0m (172.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# 모델 정의\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=x_train.shape[1:3]),  # 활성화 함수 변경\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.8061 - loss: 0.6258 \n",
      "Epoch 1: val_acc improved from -inf to 1.00000, saving model to models/model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - acc: 0.8164 - loss: 0.6025 - val_acc: 1.0000 - val_loss: 0.0708 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 0.0573\n",
      "Epoch 2: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 0.0558 - val_acc: 1.0000 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m33/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 0.0084\n",
      "Epoch 3: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 0.0082 - val_acc: 1.0000 - val_loss: 0.0032 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 0.0029\n",
      "Epoch 4: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0028 - val_acc: 1.0000 - val_loss: 0.0015 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 0.0014\n",
      "Epoch 5: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0014 - val_acc: 1.0000 - val_loss: 8.8840e-04 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.1410e-04\n",
      "Epoch 6: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.0517e-04 - val_acc: 1.0000 - val_loss: 6.0731e-04 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.7500e-04\n",
      "Epoch 7: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.6869e-04 - val_acc: 1.0000 - val_loss: 4.3960e-04 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.0855e-04\n",
      "Epoch 8: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.0525e-04 - val_acc: 1.0000 - val_loss: 3.2502e-04 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.1075e-04\n",
      "Epoch 9: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.0578e-04 - val_acc: 1.0000 - val_loss: 2.4423e-04 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.2944e-04\n",
      "Epoch 10: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.2843e-04 - val_acc: 1.0000 - val_loss: 1.9286e-04 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.8007e-04\n",
      "Epoch 11: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7892e-04 - val_acc: 1.0000 - val_loss: 1.5677e-04 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5195e-04\n",
      "Epoch 12: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5009e-04 - val_acc: 1.0000 - val_loss: 1.3041e-04 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.2561e-04\n",
      "Epoch 13: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.2425e-04 - val_acc: 1.0000 - val_loss: 1.1120e-04 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0144e-04\n",
      "Epoch 14: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0137e-04 - val_acc: 1.0000 - val_loss: 9.5688e-05 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.0237e-05\n",
      "Epoch 15: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.0145e-05 - val_acc: 1.0000 - val_loss: 8.3292e-05 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.6073e-05\n",
      "Epoch 16: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.6088e-05 - val_acc: 1.0000 - val_loss: 7.3009e-05 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.1227e-05\n",
      "Epoch 17: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.0420e-05 - val_acc: 1.0000 - val_loss: 6.4826e-05 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.0730e-05\n",
      "Epoch 18: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.0459e-05 - val_acc: 1.0000 - val_loss: 5.7682e-05 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.4627e-05\n",
      "Epoch 19: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.4150e-05 - val_acc: 1.0000 - val_loss: 5.1950e-05 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.0045e-05\n",
      "Epoch 20: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.9532e-05 - val_acc: 1.0000 - val_loss: 4.6883e-05 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.4572e-05\n",
      "Epoch 21: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.4263e-05 - val_acc: 1.0000 - val_loss: 4.2570e-05 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.9832e-05\n",
      "Epoch 22: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.9690e-05 - val_acc: 1.0000 - val_loss: 3.8830e-05 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.5539e-05\n",
      "Epoch 23: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.5552e-05 - val_acc: 1.0000 - val_loss: 3.5619e-05 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.3909e-05\n",
      "Epoch 24: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.3696e-05 - val_acc: 1.0000 - val_loss: 3.2729e-05 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.9640e-05\n",
      "Epoch 25: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.9739e-05 - val_acc: 1.0000 - val_loss: 3.0225e-05 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7692e-05\n",
      "Epoch 26: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7662e-05 - val_acc: 1.0000 - val_loss: 2.8008e-05 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.6008e-05\n",
      "Epoch 27: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.5950e-05 - val_acc: 1.0000 - val_loss: 2.5881e-05 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.4587e-05\n",
      "Epoch 28: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.4429e-05 - val_acc: 1.0000 - val_loss: 2.4114e-05 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.1936e-05\n",
      "Epoch 29: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.1936e-05 - val_acc: 1.0000 - val_loss: 2.2492e-05 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.1085e-05\n",
      "Epoch 30: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.1014e-05 - val_acc: 1.0000 - val_loss: 2.1010e-05 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.8946e-05\n",
      "Epoch 31: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9012e-05 - val_acc: 1.0000 - val_loss: 1.9687e-05 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.8376e-05\n",
      "Epoch 32: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8320e-05 - val_acc: 1.0000 - val_loss: 1.8495e-05 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.7059e-05\n",
      "Epoch 33: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7045e-05 - val_acc: 1.0000 - val_loss: 1.7440e-05 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6513e-05\n",
      "Epoch 34: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6383e-05 - val_acc: 1.0000 - val_loss: 1.6422e-05 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.5268e-05\n",
      "Epoch 35: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5226e-05 - val_acc: 1.0000 - val_loss: 1.5509e-05 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4048e-05\n",
      "Epoch 36: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4067e-05 - val_acc: 1.0000 - val_loss: 1.4678e-05 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3212e-05\n",
      "Epoch 37: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3218e-05 - val_acc: 1.0000 - val_loss: 1.3872e-05 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.3085e-05\n",
      "Epoch 38: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3025e-05 - val_acc: 1.0000 - val_loss: 1.3167e-05 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.2169e-05\n",
      "Epoch 39: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.2156e-05 - val_acc: 1.0000 - val_loss: 1.2492e-05 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1697e-05\n",
      "Epoch 40: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1658e-05 - val_acc: 1.0000 - val_loss: 1.1885e-05 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1166e-05\n",
      "Epoch 41: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1116e-05 - val_acc: 1.0000 - val_loss: 1.1304e-05 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0320e-05\n",
      "Epoch 42: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0320e-05 - val_acc: 1.0000 - val_loss: 1.0782e-05 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0671e-05\n",
      "Epoch 43: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0520e-05 - val_acc: 1.0000 - val_loss: 1.0253e-05 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.3243e-06\n",
      "Epoch 44: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.3255e-06 - val_acc: 1.0000 - val_loss: 9.7862e-06 - learning_rate: 0.0010\n",
      "Epoch 45/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.8734e-06\n",
      "Epoch 45: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.8883e-06 - val_acc: 1.0000 - val_loss: 9.3541e-06 - learning_rate: 0.0010\n",
      "Epoch 46/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.6996e-06\n",
      "Epoch 46: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.6763e-06 - val_acc: 1.0000 - val_loss: 8.9434e-06 - learning_rate: 0.0010\n",
      "Epoch 47/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.4942e-06\n",
      "Epoch 47: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.4412e-06 - val_acc: 1.0000 - val_loss: 8.5616e-06 - learning_rate: 0.0010\n",
      "Epoch 48/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.3408e-06\n",
      "Epoch 48: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.2457e-06 - val_acc: 1.0000 - val_loss: 8.2012e-06 - learning_rate: 0.0010\n",
      "Epoch 49/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.8556e-06\n",
      "Epoch 49: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.7799e-06 - val_acc: 1.0000 - val_loss: 7.8622e-06 - learning_rate: 0.0010\n",
      "Epoch 50/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.4574e-06\n",
      "Epoch 50: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.4493e-06 - val_acc: 1.0000 - val_loss: 7.5288e-06 - learning_rate: 0.0010\n",
      "Epoch 51/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.7826e-06\n",
      "Epoch 51: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.7953e-06 - val_acc: 1.0000 - val_loss: 7.2289e-06 - learning_rate: 0.0010\n",
      "Epoch 52/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.0551e-06\n",
      "Epoch 52: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.9794e-06 - val_acc: 1.0000 - val_loss: 7.0845e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.4613e-06\n",
      "Epoch 53: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.4692e-06 - val_acc: 1.0000 - val_loss: 6.9355e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.2306e-06\n",
      "Epoch 54: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.2526e-06 - val_acc: 1.0000 - val_loss: 6.7995e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.0716e-06\n",
      "Epoch 55: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.1056e-06 - val_acc: 1.0000 - val_loss: 6.6626e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.1482e-06\n",
      "Epoch 56: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.1433e-06 - val_acc: 1.0000 - val_loss: 6.5257e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.1109e-06\n",
      "Epoch 57: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.1075e-06 - val_acc: 1.0000 - val_loss: 6.3842e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.3185e-06\n",
      "Epoch 58: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.2362e-06 - val_acc: 1.0000 - val_loss: 6.2538e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.6229e-06\n",
      "Epoch 59: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.6463e-06 - val_acc: 1.0000 - val_loss: 6.1430e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.5011e-06\n",
      "Epoch 60: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.5266e-06 - val_acc: 1.0000 - val_loss: 6.0070e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.5487e-06\n",
      "Epoch 61: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.5394e-06 - val_acc: 1.0000 - val_loss: 5.8841e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.2363e-06\n",
      "Epoch 62: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.2640e-06 - val_acc: 1.0000 - val_loss: 5.7630e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.2256e-06\n",
      "Epoch 63: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.2373e-06 - val_acc: 1.0000 - val_loss: 5.6391e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.3286e-06\n",
      "Epoch 64: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.2971e-06 - val_acc: 1.0000 - val_loss: 5.5246e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.0723e-06\n",
      "Epoch 65: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.0729e-06 - val_acc: 1.0000 - val_loss: 5.4128e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.9203e-06\n",
      "Epoch 66: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.9237e-06 - val_acc: 1.0000 - val_loss: 5.3057e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.8732e-06\n",
      "Epoch 67: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.8732e-06 - val_acc: 1.0000 - val_loss: 5.1949e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.8016e-06\n",
      "Epoch 68: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.7900e-06 - val_acc: 1.0000 - val_loss: 5.0859e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.5768e-06\n",
      "Epoch 69: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.5924e-06 - val_acc: 1.0000 - val_loss: 4.9825e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.5831e-06\n",
      "Epoch 70: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.5750e-06 - val_acc: 1.0000 - val_loss: 4.8717e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.2908e-06\n",
      "Epoch 71: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.3172e-06 - val_acc: 1.0000 - val_loss: 4.7665e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.4419e-06\n",
      "Epoch 72: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.4307e-06 - val_acc: 1.0000 - val_loss: 4.6771e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.2340e-06\n",
      "Epoch 73: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.2285e-06 - val_acc: 1.0000 - val_loss: 4.5746e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.2187e-06\n",
      "Epoch 74: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.2141e-06 - val_acc: 1.0000 - val_loss: 4.4778e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.0738e-06\n",
      "Epoch 75: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.0769e-06 - val_acc: 1.0000 - val_loss: 4.3930e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.1227e-06\n",
      "Epoch 76: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.1027e-06 - val_acc: 1.0000 - val_loss: 4.2906e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.9007e-06\n",
      "Epoch 77: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.9032e-06 - val_acc: 1.0000 - val_loss: 4.2142e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.7660e-06\n",
      "Epoch 78: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.7747e-06 - val_acc: 1.0000 - val_loss: 4.1276e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.6472e-06\n",
      "Epoch 79: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.6650e-06 - val_acc: 1.0000 - val_loss: 4.0345e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.6723e-06\n",
      "Epoch 80: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.6742e-06 - val_acc: 1.0000 - val_loss: 3.9525e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.5434e-06\n",
      "Epoch 81: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.5508e-06 - val_acc: 1.0000 - val_loss: 3.8780e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.6129e-06\n",
      "Epoch 82: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.6012e-06 - val_acc: 1.0000 - val_loss: 3.7933e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.4904e-06\n",
      "Epoch 83: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.4852e-06 - val_acc: 1.0000 - val_loss: 3.7104e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.3621e-06\n",
      "Epoch 84: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.3639e-06 - val_acc: 1.0000 - val_loss: 3.6312e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.3453e-06\n",
      "Epoch 85: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.3442e-06 - val_acc: 1.0000 - val_loss: 3.5539e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.1589e-06\n",
      "Epoch 86: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.1735e-06 - val_acc: 1.0000 - val_loss: 3.4859e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.2166e-06\n",
      "Epoch 87: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.2104e-06 - val_acc: 1.0000 - val_loss: 3.4189e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.4117e-06\n",
      "Epoch 88: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.3622e-06 - val_acc: 1.0000 - val_loss: 3.3416e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.9378e-06\n",
      "Epoch 89: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.9573e-06 - val_acc: 1.0000 - val_loss: 3.2699e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.1175e-06\n",
      "Epoch 90: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.0929e-06 - val_acc: 1.0000 - val_loss: 3.2065e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.8915e-06\n",
      "Epoch 91: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.8952e-06 - val_acc: 1.0000 - val_loss: 3.1348e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.8974e-06\n",
      "Epoch 92: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.8913e-06 - val_acc: 1.0000 - val_loss: 3.0771e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.7487e-06\n",
      "Epoch 93: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7559e-06 - val_acc: 1.0000 - val_loss: 3.0156e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.7864e-06\n",
      "Epoch 94: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7788e-06 - val_acc: 1.0000 - val_loss: 2.9514e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.6431e-06\n",
      "Epoch 95: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.6453e-06 - val_acc: 1.0000 - val_loss: 2.8890e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.6420e-06\n",
      "Epoch 96: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.6358e-06 - val_acc: 1.0000 - val_loss: 2.8200e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.5863e-06\n",
      "Epoch 97: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.5829e-06 - val_acc: 1.0000 - val_loss: 2.7744e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.5414e-06\n",
      "Epoch 98: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.5360e-06 - val_acc: 1.0000 - val_loss: 2.7120e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.4622e-06\n",
      "Epoch 99: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.4628e-06 - val_acc: 1.0000 - val_loss: 2.6608e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.4468e-06\n",
      "Epoch 100: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.4423e-06 - val_acc: 1.0000 - val_loss: 2.5937e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.3902e-06\n",
      "Epoch 101: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3851e-06 - val_acc: 1.0000 - val_loss: 2.5397e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3210e-06\n",
      "Epoch 102: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3198e-06 - val_acc: 1.0000 - val_loss: 2.5127e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.2621e-06\n",
      "Epoch 103: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.2665e-06 - val_acc: 1.0000 - val_loss: 2.4820e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.2833e-06\n",
      "Epoch 104: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.2801e-06 - val_acc: 1.0000 - val_loss: 2.4512e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.3240e-06\n",
      "Epoch 105: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3095e-06 - val_acc: 1.0000 - val_loss: 2.4289e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.3644e-06\n",
      "Epoch 106: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3403e-06 - val_acc: 1.0000 - val_loss: 2.4075e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.1533e-06\n",
      "Epoch 107: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.1603e-06 - val_acc: 1.0000 - val_loss: 2.3758e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.1392e-06\n",
      "Epoch 108: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.1456e-06 - val_acc: 1.0000 - val_loss: 2.3432e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.1192e-06\n",
      "Epoch 109: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.1221e-06 - val_acc: 1.0000 - val_loss: 2.3283e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.2818e-06\n",
      "Epoch 110: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.2415e-06 - val_acc: 1.0000 - val_loss: 2.3059e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.0829e-06\n",
      "Epoch 111: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0851e-06 - val_acc: 1.0000 - val_loss: 2.2659e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.9476e-06\n",
      "Epoch 112: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9607e-06 - val_acc: 1.0000 - val_loss: 2.2445e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.0925e-06\n",
      "Epoch 113: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0838e-06 - val_acc: 1.0000 - val_loss: 2.2212e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.0591e-06\n",
      "Epoch 114: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0527e-06 - val_acc: 1.0000 - val_loss: 2.1951e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.9638e-06\n",
      "Epoch 115: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9714e-06 - val_acc: 1.0000 - val_loss: 2.1644e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.9846e-06\n",
      "Epoch 116: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9815e-06 - val_acc: 1.0000 - val_loss: 2.1392e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9391e-06\n",
      "Epoch 117: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9454e-06 - val_acc: 1.0000 - val_loss: 2.1150e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.8834e-06\n",
      "Epoch 118: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8901e-06 - val_acc: 1.0000 - val_loss: 2.0899e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.8946e-06\n",
      "Epoch 119: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8983e-06 - val_acc: 1.0000 - val_loss: 2.0573e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.9418e-06\n",
      "Epoch 120: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9322e-06 - val_acc: 1.0000 - val_loss: 2.0303e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.8800e-06\n",
      "Epoch 121: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8758e-06 - val_acc: 1.0000 - val_loss: 2.0079e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.7556e-06\n",
      "Epoch 122: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7674e-06 - val_acc: 1.0000 - val_loss: 1.9837e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.8146e-06\n",
      "Epoch 123: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8132e-06 - val_acc: 1.0000 - val_loss: 1.9576e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7629e-06\n",
      "Epoch 124: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7669e-06 - val_acc: 1.0000 - val_loss: 1.9325e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.7437e-06\n",
      "Epoch 125: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7467e-06 - val_acc: 1.0000 - val_loss: 1.9064e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.6922e-06\n",
      "Epoch 126: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6979e-06 - val_acc: 1.0000 - val_loss: 1.8803e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.6593e-06\n",
      "Epoch 127: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6662e-06 - val_acc: 1.0000 - val_loss: 1.8543e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.7275e-06\n",
      "Epoch 128: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7219e-06 - val_acc: 1.0000 - val_loss: 1.8245e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.6456e-06\n",
      "Epoch 129: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6500e-06 - val_acc: 1.0000 - val_loss: 1.8030e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.6721e-06\n",
      "Epoch 130: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6668e-06 - val_acc: 1.0000 - val_loss: 1.7825e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6592e-06\n",
      "Epoch 131: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6509e-06 - val_acc: 1.0000 - val_loss: 1.7565e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.5705e-06\n",
      "Epoch 132: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5753e-06 - val_acc: 1.0000 - val_loss: 1.7267e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.5330e-06\n",
      "Epoch 133: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5380e-06 - val_acc: 1.0000 - val_loss: 1.7062e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.6414e-06\n",
      "Epoch 134: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6261e-06 - val_acc: 1.0000 - val_loss: 1.6848e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.5113e-06\n",
      "Epoch 135: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5116e-06 - val_acc: 1.0000 - val_loss: 1.6615e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.5495e-06\n",
      "Epoch 136: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5440e-06 - val_acc: 1.0000 - val_loss: 1.6354e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.5963e-06\n",
      "Epoch 137: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5804e-06 - val_acc: 1.0000 - val_loss: 1.6158e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5082e-06\n",
      "Epoch 138: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4998e-06 - val_acc: 1.0000 - val_loss: 1.5898e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.3827e-06\n",
      "Epoch 139: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3936e-06 - val_acc: 1.0000 - val_loss: 1.5702e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.4704e-06\n",
      "Epoch 140: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4651e-06 - val_acc: 1.0000 - val_loss: 1.5413e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.3436e-06\n",
      "Epoch 141: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3540e-06 - val_acc: 1.0000 - val_loss: 1.5227e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.3978e-06\n",
      "Epoch 142: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3964e-06 - val_acc: 1.0000 - val_loss: 1.5004e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.3696e-06\n",
      "Epoch 143: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3697e-06 - val_acc: 1.0000 - val_loss: 1.4706e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.3505e-06\n",
      "Epoch 144: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3499e-06 - val_acc: 1.0000 - val_loss: 1.4529e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3012e-06\n",
      "Epoch 145: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3052e-06 - val_acc: 1.0000 - val_loss: 1.4296e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.3068e-06\n",
      "Epoch 146: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3063e-06 - val_acc: 1.0000 - val_loss: 1.4063e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3133e-06\n",
      "Epoch 147: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3086e-06 - val_acc: 1.0000 - val_loss: 1.3914e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.3280e-06\n",
      "Epoch 148: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3186e-06 - val_acc: 1.0000 - val_loss: 1.3662e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.3075e-06\n",
      "Epoch 149: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.2977e-06 - val_acc: 1.0000 - val_loss: 1.3551e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.3094e-06\n",
      "Epoch 150: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.2986e-06 - val_acc: 1.0000 - val_loss: 1.3225e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.2226e-06\n",
      "Epoch 151: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.2227e-06 - val_acc: 1.0000 - val_loss: 1.3066e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.2050e-06\n",
      "Epoch 152: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.2062e-06 - val_acc: 1.0000 - val_loss: 1.2992e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1707e-06\n",
      "Epoch 153: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1742e-06 - val_acc: 1.0000 - val_loss: 1.2908e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1552e-06\n",
      "Epoch 154: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1570e-06 - val_acc: 1.0000 - val_loss: 1.2824e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 155/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1715e-06\n",
      "Epoch 155: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1732e-06 - val_acc: 1.0000 - val_loss: 1.2722e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 156/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1575e-06\n",
      "Epoch 156: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1597e-06 - val_acc: 1.0000 - val_loss: 1.2647e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 157/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1303e-06\n",
      "Epoch 157: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1332e-06 - val_acc: 1.0000 - val_loss: 1.2517e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 158/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.2212e-06\n",
      "Epoch 158: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.2044e-06 - val_acc: 1.0000 - val_loss: 1.2424e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 159/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1384e-06\n",
      "Epoch 159: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1386e-06 - val_acc: 1.0000 - val_loss: 1.2331e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1374e-06\n",
      "Epoch 160: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1346e-06 - val_acc: 1.0000 - val_loss: 1.2182e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 161/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0891e-06\n",
      "Epoch 161: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0938e-06 - val_acc: 1.0000 - val_loss: 1.2089e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 162/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0838e-06\n",
      "Epoch 162: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0878e-06 - val_acc: 1.0000 - val_loss: 1.1967e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 163/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1308e-06\n",
      "Epoch 163: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.1296e-06 - val_acc: 1.0000 - val_loss: 1.1865e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 164/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1149e-06\n",
      "Epoch 164: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1081e-06 - val_acc: 1.0000 - val_loss: 1.1791e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 165/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1155e-06\n",
      "Epoch 165: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1101e-06 - val_acc: 1.0000 - val_loss: 1.1660e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 166/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0668e-06\n",
      "Epoch 166: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0678e-06 - val_acc: 1.0000 - val_loss: 1.1576e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 167/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0677e-06\n",
      "Epoch 167: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0649e-06 - val_acc: 1.0000 - val_loss: 1.1502e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 168/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0733e-06\n",
      "Epoch 168: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0691e-06 - val_acc: 1.0000 - val_loss: 1.1409e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 169/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0413e-06\n",
      "Epoch 169: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0416e-06 - val_acc: 1.0000 - val_loss: 1.1325e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 170/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0449e-06\n",
      "Epoch 170: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0410e-06 - val_acc: 1.0000 - val_loss: 1.1241e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 171/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1084e-06\n",
      "Epoch 171: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0950e-06 - val_acc: 1.0000 - val_loss: 1.1045e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 172/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.8909e-07\n",
      "Epoch 172: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.9285e-07 - val_acc: 1.0000 - val_loss: 1.0906e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 173/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0031e-06\n",
      "Epoch 173: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0036e-06 - val_acc: 1.0000 - val_loss: 1.0813e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 174/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.7251e-07\n",
      "Epoch 174: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.7587e-07 - val_acc: 1.0000 - val_loss: 1.0757e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 175/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.3132e-07\n",
      "Epoch 175: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.3934e-07 - val_acc: 1.0000 - val_loss: 1.0701e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 176/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.6136e-07\n",
      "Epoch 176: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.6435e-07 - val_acc: 1.0000 - val_loss: 1.0617e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 177/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0075e-06\n",
      "Epoch 177: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0014e-06 - val_acc: 1.0000 - val_loss: 1.0552e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 178/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.9976e-07\n",
      "Epoch 178: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.9284e-07 - val_acc: 1.0000 - val_loss: 1.0459e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 179/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.7439e-07\n",
      "Epoch 179: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.7095e-07 - val_acc: 1.0000 - val_loss: 1.0356e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 180/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.5910e-07\n",
      "Epoch 180: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.5737e-07 - val_acc: 1.0000 - val_loss: 1.0291e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 181/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.2846e-07\n",
      "Epoch 181: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.3059e-07 - val_acc: 1.0000 - val_loss: 1.0217e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 182/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.7866e-07\n",
      "Epoch 182: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.7101e-07 - val_acc: 1.0000 - val_loss: 1.0123e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 183/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.9516e-07\n",
      "Epoch 183: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.9771e-07 - val_acc: 1.0000 - val_loss: 1.0002e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 184/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.7559e-07\n",
      "Epoch 184: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.7802e-07 - val_acc: 1.0000 - val_loss: 9.8161e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 185/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.9252e-07\n",
      "Epoch 185: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.9282e-07 - val_acc: 1.0000 - val_loss: 9.6578e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 186/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.7261e-07\n",
      "Epoch 186: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.7360e-07 - val_acc: 1.0000 - val_loss: 9.5926e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 187/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.4014e-07\n",
      "Epoch 187: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.2848e-07 - val_acc: 1.0000 - val_loss: 9.4436e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 188/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.5339e-07\n",
      "Epoch 188: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.5420e-07 - val_acc: 1.0000 - val_loss: 9.3039e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 189/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.4114e-07\n",
      "Epoch 189: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.4485e-07 - val_acc: 1.0000 - val_loss: 9.1642e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 190/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.2740e-07\n",
      "Epoch 190: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.2719e-07 - val_acc: 1.0000 - val_loss: 9.0431e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 191/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.2945e-07\n",
      "Epoch 191: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.2930e-07 - val_acc: 1.0000 - val_loss: 8.9686e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 192/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.7224e-07\n",
      "Epoch 192: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.6454e-07 - val_acc: 1.0000 - val_loss: 8.9127e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 193/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.9660e-07\n",
      "Epoch 193: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.9989e-07 - val_acc: 1.0000 - val_loss: 8.8382e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 194/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.1407e-07\n",
      "Epoch 194: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.1347e-07 - val_acc: 1.0000 - val_loss: 8.7079e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 195/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.9949e-07\n",
      "Epoch 195: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.9950e-07 - val_acc: 1.0000 - val_loss: 8.6054e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 196/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.6806e-07\n",
      "Epoch 196: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.7117e-07 - val_acc: 1.0000 - val_loss: 8.5030e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 197/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.7257e-07\n",
      "Epoch 197: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.7393e-07 - val_acc: 1.0000 - val_loss: 8.4005e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 198/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.7518e-07\n",
      "Epoch 198: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.7467e-07 - val_acc: 1.0000 - val_loss: 8.3260e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 199/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.3233e-07\n",
      "Epoch 199: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.3870e-07 - val_acc: 1.0000 - val_loss: 8.3074e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 200/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.5978e-07\n",
      "Epoch 200: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.5692e-07 - val_acc: 1.0000 - val_loss: 8.2049e-07 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# 모델 학습 및 저장\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/model.keras', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),  # 확장자 변경\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")\n",
    "# 모델 저장\n",
    "model.save('models/model.keras')  # 확장자 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[94,  0],\n",
       "        [ 0, 34]],\n",
       "\n",
       "       [[81,  0],\n",
       "        [ 0, 47]],\n",
       "\n",
       "       [[81,  0],\n",
       "        [ 0, 47]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/model.keras')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
